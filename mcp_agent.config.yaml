execution_engine: asyncio

# MCP server configurations
mcp:
  servers:
    # Fetch server for basic web retrieval
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]

    context7:
      command: "npx"
      args: ["-y", "g-search-mcp"]

    # Filesystem server for writing reports
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem"]

    sequential-thinking:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-sequential-thinking"]

openai:
  default_model: gpt-4o
